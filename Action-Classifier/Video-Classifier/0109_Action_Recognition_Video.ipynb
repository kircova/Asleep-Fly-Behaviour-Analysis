{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2gRWrwQFuP5"
      },
      "source": [
        "## Imports and Lib Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb3HNI2OG35K",
        "outputId": "a4a793fa-e887-4cdc-e6b9-ea926c34c3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting remotezip\n",
            "  Downloading remotezip-0.12.1.tar.gz (7.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from remotezip) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from remotezip) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2023.7.22)\n",
            "Building wheels for collected packages: remotezip\n",
            "  Building wheel for remotezip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for remotezip: filename=remotezip-0.12.1-py3-none-any.whl size=7934 sha256=4d1390acc4536cf96cc9f9c931fdcb0046e6cb4fabd982c2b4742526d86b1b11\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/76/04/beed1a6df4eb7430ee13c3900746edd517e5e597298d1f73f3\n",
            "Successfully built remotezip\n",
            "Installing collected packages: einops, remotezip\n",
            "Successfully installed einops-0.6.1 remotezip-0.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install remotezip tqdm opencv-python einops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkEH22jwFgJD",
        "outputId": "cdc6ee5f-fb56-4c6a-cd87-86a15c5a2c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: remotezip in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from remotezip) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from remotezip) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2023.7.22)\n",
            "Collecting collection\n",
            "  Downloading collection-0.1.6.tar.gz (5.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: collection\n",
            "  Building wheel for collection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for collection: filename=collection-0.1.6-py3-none-any.whl size=5099 sha256=3c74dc3d17c45d498031b46d67ee76f102456b702033b84c1083ed9af735b26a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/70/eb/1d28795e9384ab3b9be6359bdde9e1652f6e7dab9d26844f70\n",
            "Successfully built collection\n",
            "Installing collected packages: collection\n",
            "Successfully installed collection-0.1.6\n",
            "Collecting picklable-itertools\n",
            "  Downloading picklable-itertools-0.1.1.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from picklable-itertools) (1.16.0)\n",
            "Building wheels for collected packages: picklable-itertools\n",
            "  Building wheel for picklable-itertools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for picklable-itertools: filename=picklable_itertools-0.1.1-py3-none-any.whl size=15570 sha256=d14c3e8988fb7b2e62418f6d8903944ec7dad3ccec654dfceebcb2a40438e103\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/19/34/8fc5b4c7d645b73b2e61f5b48699cefda12a903666e5170b84\n",
            "Successfully built picklable-itertools\n",
            "Installing collected packages: picklable-itertools\n",
            "Successfully installed picklable-itertools-0.1.1\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Collecting random2\n",
            "  Downloading random2-1.0.1.zip (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: random2\n",
            "  Building wheel for random2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for random2: filename=random2-1.0.1-py3-none-any.whl size=12041 sha256=4eeae91a0249e385b8fda0aacdfcb0c87cd9b3cabc3c016e4ef8494ff479942d\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1f/84/8713326a151c1638e7a00202e4074b46e839d22b7d22f8400f\n",
            "Successfully built random2\n",
            "Installing collected packages: random2\n",
            "Successfully installed random2-1.0.1\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.14)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: remotezip in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from remotezip) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from remotezip) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2023.7.22)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.23.5)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.10.1)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (0.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (23.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->statsmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->statsmodels) (2023.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels) (1.16.0)\n",
            "Requirement already satisfied: remotezip in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.5.2.52 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.5.2.52\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install seaborn\n",
        "!pip install keras\n",
        "!pip install remotezip\n",
        "!pip install collection\n",
        "!pip install picklable-itertools\n",
        "!pip install pathlib\n",
        "!pip install random2\n",
        "!pip install tensorflow\n",
        "!pip install remotezip tqdm opencv-python einops\n",
        "!pip install -U statsmodels\n",
        "!pip install remotezip tqdm opencv-python==4.5.2.52 opencv-python-headless==4.5.2.52 tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doMwFinTG8__",
        "outputId": "a06dd993-ce0c-4938-b7b6-1c9c132c118d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-models-official\n",
            "  Downloading tf_models_official-2.13.1-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.29.36)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (9.4.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official)\n",
            "  Downloading immutabledict-3.0.0-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.16)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.23.5)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.8.0.76)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.5.3)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (9.0.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (2.0.7)\n",
            "Collecting pyyaml<5.4.0,>=5.1 (from tf-models-official)\n",
            "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.4/269.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from tf-models-official)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.10.1)\n",
            "Collecting sentencepiece (from tf-models-official)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (4.9.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (0.14.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.13.0 (from tf-models-official)\n",
            "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.13.0 (from tf-models-official)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.22.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.22.0->tf-models-official) (2023.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow~=2.13.0->tf-models-official)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (67.7.2)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow~=2.13.0->tf-models-official)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow~=2.13.0->tf-models-official)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (2.3.0)\n",
            "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow~=2.13.0->tf-models-official)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.13.0->tf-models-official) (0.33.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->tf-models-official) (3.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official) (4.9)\n",
            "Collecting portalocker (from sacrebleu->tf-models-official)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->tf-models-official)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->tf-models-official) (4.9.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official) (1.2.2)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.4.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.13.0->tf-models-official) (0.41.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (6.0.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (3.16.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.60.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official) (3.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official) (2.3.7)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow~=2.13.0->tf-models-official) (3.2.2)\n",
            "Building wheels for collected packages: pyyaml, seqeval\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp310-cp310-linux_x86_64.whl size=44635 sha256=5b3a1e04a486eeddead8576c29c350635cfa9d2c12c1ddaf3306d10b86053104\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/a9/6a/d0a6981a8dbb698845178818642f72ce179f14336908c7df01\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=ace593f5e40e04892ad7714b95aa4b7f33476ed6c56f755d5da5508ab3932c29\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built pyyaml seqeval\n",
            "Installing collected packages: sentencepiece, typing-extensions, tensorflow-model-optimization, tensorflow-estimator, pyyaml, portalocker, keras, immutabledict, colorama, sacrebleu, seqeval, tensorboard, tensorflow, tensorflow-text, tf-models-official\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.7.2 requires PyYAML>=5.4.1, but you have pyyaml 5.3.1 which is incompatible.\n",
            "pydantic 2.2.1 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.6.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 immutabledict-3.0.0 keras-2.13.1 portalocker-2.7.0 pyyaml-5.3.1 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.13.0 tf-models-official-2.13.1 typing-extensions-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvh0nhldF1bB",
        "outputId": "bd64ebd4-ae6c-460e-b78e-4256ea2a2684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: remotezip in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from remotezip) (2.31.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from remotezip) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->remotezip) (2023.7.22)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install remotezip tqdm opencv-python\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p048TbiuF4GJ"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import remotezip as rz\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
        "from official.projects.movinet.modeling import movinet\n",
        "from official.projects.movinet.modeling import movinet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZGo7Rxmnr35"
      },
      "source": [
        "# Video Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKlG9xJHnvgv"
      },
      "outputs": [],
      "source": [
        "URL = 'https://storage.googleapis.com/fly-action-100/Action_100.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9oVvfsRAGGO"
      },
      "outputs": [],
      "source": [
        "def list_files_from_zip_url(zip_url):\n",
        "  \"\"\" List the files in each class of the dataset given a URL with the zip file.\n",
        "\n",
        "    Args:\n",
        "      zip_url: A URL from which the files can be extracted from.\n",
        "\n",
        "    Returns:\n",
        "      List of files in each of the classes.\n",
        "  \"\"\"\n",
        "  files = []\n",
        "  with rz.RemoteZip(zip_url) as zip:\n",
        "    for zip_info in zip.infolist():\n",
        "      if zip_info.filename[0:3] != \"__M\":\n",
        "        files.append(zip_info.filename)\n",
        "  return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcrurz1ZAHP2",
        "outputId": "edb91209-2775-41c8-ebff-547e53e5d739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Action_100/v_Pumping_g01_c8.avi',\n",
              " 'Action_100/v_Grooming_g01_c36.avi',\n",
              " 'Action_100/v_Grooming_g01_c22.avi',\n",
              " 'Action_100/v_Feeding_g01_c96.avi',\n",
              " 'Action_100/v_Feeding_g01_c82.avi',\n",
              " 'Action_100/v_Feeding_g01_c69.avi',\n",
              " 'Action_100/v_Feeding_g01_c55.avi',\n",
              " 'Action_100/v_Feeding_g01_c41.avi',\n",
              " 'Action_100/v_Pumping_g01_c50.avi',\n",
              " 'Action_100/v_Pumping_g01_c44.avi',\n",
              " 'Action_100/v_Pumping_g01_c78.avi',\n",
              " 'Action_100/v_Pumping_g01_c93.avi',\n",
              " 'Action_100/v_Pumping_g01_c87.avi',\n",
              " 'Action_100/v_Pumping_g01_c86.avi',\n",
              " 'Action_100/v_Pumping_g01_c92.avi',\n",
              " 'Action_100/v_Pumping_g01_c79.avi',\n",
              " 'Action_100/v_Pumping_g01_c45.avi',\n",
              " 'Action_100/v_Pumping_g01_c51.avi',\n",
              " 'Action_100/v_Feeding_g01_c40.avi',\n",
              " 'Action_100/v_Feeding_g01_c54.avi',\n",
              " 'Action_100/v_Feeding_g01_c68.avi',\n",
              " 'Action_100/v_Feeding_g01_c83.avi',\n",
              " 'Action_100/v_Feeding_g01_c97.avi',\n",
              " 'Action_100/v_Grooming_g01_c23.avi',\n",
              " 'Action_100/v_Grooming_g01_c37.avi',\n",
              " 'Action_100/v_Pumping_g01_c9.avi',\n",
              " 'Action_100/v_Grooming_g01_c21.avi',\n",
              " 'Action_100/v_Grooming_g01_c35.avi',\n",
              " 'Action_100/v_Feeding_g01_c81.avi',\n",
              " 'Action_100/v_Feeding_g01_c95.avi',\n",
              " 'Action_100/v_Feeding_g01_c42.avi',\n",
              " 'Action_100/v_Feeding_g01_c56.avi',\n",
              " 'Action_100/v_Pumping_g01_c47.avi',\n",
              " 'Action_100/v_Pumping_g01_c53.avi',\n",
              " 'Action_100/v_Pumping_g01_c84.avi',\n",
              " 'Action_100/v_Pumping_g01_c90.avi',\n",
              " 'Action_100/v_Pumping_g01_c91.avi',\n",
              " 'Action_100/v_Pumping_g01_c85.avi',\n",
              " 'Action_100/v_Pumping_g01_c52.avi',\n",
              " 'Action_100/v_Pumping_g01_c46.avi',\n",
              " 'Action_100/v_Feeding_g01_c57.avi',\n",
              " 'Action_100/v_Feeding_g01_c43.avi',\n",
              " 'Action_100/v_Feeding_g01_c94.avi',\n",
              " 'Action_100/v_Feeding_g01_c80.avi',\n",
              " 'Action_100/v_Grooming_g01_c34.avi',\n",
              " 'Action_100/v_Grooming_g01_c20.avi',\n",
              " 'Action_100/v_Grooming_g01_c24.avi',\n",
              " 'Action_100/v_Grooming_g01_c30.avi',\n",
              " 'Action_100/v_Grooming_g01_c18.avi',\n",
              " 'Action_100/v_Feeding_g01_c84.avi',\n",
              " 'Action_100/v_Feeding_g01_c90.avi',\n",
              " 'Action_100/v_Feeding_g01_c47.avi',\n",
              " 'Action_100/v_Feeding_g01_c53.avi',\n",
              " 'Action_100/v_Pumping_g01_c42.avi',\n",
              " 'Action_100/v_Pumping_g01_c56.avi',\n",
              " 'Action_100/v_Pumping_g01_c81.avi',\n",
              " 'Action_100/v_Pumping_g01_c95.avi',\n",
              " 'Action_100/v_Pumping_g01_c94.avi',\n",
              " 'Action_100/v_Pumping_g01_c80.avi',\n",
              " 'Action_100/v_Pumping_g01_c57.avi',\n",
              " 'Action_100/v_Pumping_g01_c43.avi',\n",
              " 'Action_100/v_Feeding_g01_c52.avi',\n",
              " 'Action_100/v_Feeding_g01_c46.avi',\n",
              " 'Action_100/v_Feeding_g01_c91.avi',\n",
              " 'Action_100/v_Feeding_g01_c85.avi',\n",
              " 'Action_100/v_Grooming_g01_c19.avi',\n",
              " 'Action_100/v_Grooming_g01_c31.avi',\n",
              " 'Action_100/v_Grooming_g01_c25.avi',\n",
              " 'Action_100/v_Grooming_g01_c9.avi',\n",
              " 'Action_100/v_Grooming_g01_c33.avi',\n",
              " 'Action_100/v_Grooming_g01_c27.avi',\n",
              " 'Action_100/v_Feeding_g01_c93.avi',\n",
              " 'Action_100/v_Feeding_g01_c87.avi',\n",
              " 'Action_100/v_Feeding_g01_c50.avi',\n",
              " 'Action_100/v_Feeding_g01_c44.avi',\n",
              " 'Action_100/v_Feeding_g01_c78.avi',\n",
              " 'Action_100/v_Pumping_g01_c69.avi',\n",
              " 'Action_100/v_Pumping_g01_c55.avi',\n",
              " 'Action_100/v_Pumping_g01_c41.avi',\n",
              " 'Action_100/v_Pumping_g01_c96.avi',\n",
              " 'Action_100/v_Pumping_g01_c82.avi',\n",
              " 'Action_100/v_Pumping_g01_c83.avi',\n",
              " 'Action_100/v_Pumping_g01_c97.avi',\n",
              " 'Action_100/v_Pumping_g01_c40.avi',\n",
              " 'Action_100/v_Pumping_g01_c54.avi',\n",
              " 'Action_100/v_Pumping_g01_c68.avi',\n",
              " 'Action_100/v_Feeding_g01_c79.avi',\n",
              " 'Action_100/v_Feeding_g01_c45.avi',\n",
              " 'Action_100/v_Feeding_g01_c51.avi',\n",
              " 'Action_100/v_Feeding_g01_c86.avi',\n",
              " 'Action_100/v_Feeding_g01_c92.avi',\n",
              " 'Action_100/v_Grooming_g01_c26.avi',\n",
              " 'Action_100/v_Grooming_g01_c32.avi',\n",
              " 'Action_100/v_Grooming_g01_c8.avi',\n",
              " 'Action_100/v_Grooming_g01_c96.avi',\n",
              " 'Action_100/v_Grooming_g01_c82.avi',\n",
              " 'Action_100/v_Grooming_g01_c69.avi',\n",
              " 'Action_100/v_Grooming_g01_c55.avi',\n",
              " 'Action_100/v_Grooming_g01_c41.avi',\n",
              " 'Action_100/v_Feeding_g01_c36.avi',\n",
              " 'Action_100/v_Feeding_g01_c22.avi',\n",
              " 'Action_100/v_Pumping_g01_c33.avi',\n",
              " 'Action_100/v_Feeding_g01_c3.avi',\n",
              " 'Action_100/v_Pumping_g01_c27.avi',\n",
              " 'Action_100/v_Pumping_g01_c26.avi',\n",
              " 'Action_100/v_Pumping_g01_c32.avi',\n",
              " 'Action_100/v_Feeding_g01_c2.avi',\n",
              " 'Action_100/v_Feeding_g01_c23.avi',\n",
              " 'Action_100/v_Feeding_g01_c37.avi',\n",
              " 'Action_100/v_Grooming_g01_c40.avi',\n",
              " 'Action_100/v_Grooming_g01_c54.avi',\n",
              " 'Action_100/v_Grooming_g01_c68.avi',\n",
              " 'Action_100/v_Grooming_g01_c83.avi',\n",
              " 'Action_100/v_Grooming_g01_c97.avi',\n",
              " 'Action_100/v_Grooming_g01_c81.avi',\n",
              " 'Action_100/v_Grooming_g01_c95.avi',\n",
              " 'Action_100/v_Grooming_g01_c42.avi',\n",
              " 'Action_100/v_Grooming_g01_c56.avi',\n",
              " 'Action_100/v_Feeding_g01_c21.avi',\n",
              " 'Action_100/v_Feeding_g01_c35.avi',\n",
              " 'Action_100/v_Pumping_g01_c24.avi',\n",
              " 'Action_100/v_Feeding_g01_c0.avi',\n",
              " 'Action_100/v_Pumping_g01_c30.avi',\n",
              " 'Action_100/v_Pumping_g01_c18.avi',\n",
              " 'Action_100/v_Pumping_g01_c19.avi',\n",
              " 'Action_100/v_Feeding_g01_c1.avi',\n",
              " 'Action_100/v_Pumping_g01_c31.avi',\n",
              " 'Action_100/v_Pumping_g01_c25.avi',\n",
              " 'Action_100/v_Feeding_g01_c34.avi',\n",
              " 'Action_100/v_Feeding_g01_c20.avi',\n",
              " 'Action_100/v_Grooming_g01_c57.avi',\n",
              " 'Action_100/v_Grooming_g01_c43.avi',\n",
              " 'Action_100/v_Grooming_g01_c94.avi',\n",
              " 'Action_100/v_Grooming_g01_c80.avi',\n",
              " 'Action_100/v_Grooming_g01_c84.avi',\n",
              " 'Action_100/v_Grooming_g01_c90.avi',\n",
              " 'Action_100/v_Grooming_g01_c47.avi',\n",
              " 'Action_100/v_Grooming_g01_c53.avi',\n",
              " 'Action_100/v_Feeding_g01_c24.avi',\n",
              " 'Action_100/v_Feeding_g01_c30.avi',\n",
              " 'Action_100/v_Feeding_g01_c18.avi',\n",
              " 'Action_100/v_Pumping_g01_c21.avi',\n",
              " 'Action_100/v_Pumping_g01_c35.avi',\n",
              " 'Action_100/v_Feeding_g01_c5.avi',\n",
              " 'Action_100/v_Pumping_g01_c34.avi',\n",
              " 'Action_100/v_Feeding_g01_c4.avi',\n",
              " 'Action_100/v_Pumping_g01_c20.avi',\n",
              " 'Action_100/v_Feeding_g01_c19.avi',\n",
              " 'Action_100/v_Feeding_g01_c31.avi',\n",
              " 'Action_100/v_Feeding_g01_c25.avi',\n",
              " 'Action_100/v_Grooming_g01_c52.avi',\n",
              " 'Action_100/v_Grooming_g01_c46.avi',\n",
              " 'Action_100/v_Grooming_g01_c91.avi',\n",
              " 'Action_100/v_Grooming_g01_c85.avi',\n",
              " 'Action_100/v_Grooming_g01_c93.avi',\n",
              " 'Action_100/v_Grooming_g01_c87.avi',\n",
              " 'Action_100/v_Grooming_g01_c50.avi',\n",
              " 'Action_100/v_Grooming_g01_c44.avi',\n",
              " 'Action_100/v_Grooming_g01_c78.avi',\n",
              " 'Action_100/v_Feeding_g01_c33.avi',\n",
              " 'Action_100/v_Feeding_g01_c27.avi',\n",
              " 'Action_100/v_Feeding_g01_c6.avi',\n",
              " 'Action_100/v_Pumping_g01_c36.avi',\n",
              " 'Action_100/v_Pumping_g01_c22.avi',\n",
              " 'Action_100/v_Pumping_g01_c23.avi',\n",
              " 'Action_100/v_Feeding_g01_c7.avi',\n",
              " 'Action_100/v_Pumping_g01_c37.avi',\n",
              " 'Action_100/v_Feeding_g01_c26.avi',\n",
              " 'Action_100/v_Feeding_g01_c32.avi',\n",
              " 'Action_100/v_Grooming_g01_c79.avi',\n",
              " 'Action_100/v_Grooming_g01_c45.avi',\n",
              " 'Action_100/v_Grooming_g01_c51.avi',\n",
              " 'Action_100/v_Grooming_g01_c86.avi',\n",
              " 'Action_100/v_Grooming_g01_c92.avi',\n",
              " 'Action_100/v_Grooming_g01_c48.avi',\n",
              " 'Action_100/v_Grooming_g01_c74.avi',\n",
              " 'Action_100/v_Grooming_g01_c60.avi',\n",
              " 'Action_100/v_Feeding_g01_c17.avi',\n",
              " 'Action_100/v_Pumping_g01_c12.avi',\n",
              " 'Action_100/v_Pumping_g01_c13.avi',\n",
              " 'Action_100/v_Feeding_g01_c16.avi',\n",
              " 'Action_100/v_Grooming_g01_c61.avi',\n",
              " 'Action_100/v_Grooming_g01_c75.avi',\n",
              " 'Action_100/v_Grooming_g01_c49.avi',\n",
              " 'Action_100/v_Grooming_g01_c88.avi',\n",
              " 'Action_100/v_Grooming_g01_c63.avi',\n",
              " 'Action_100/v_Grooming_g01_c77.avi',\n",
              " 'Action_100/v_Feeding_g01_c28.avi',\n",
              " 'Action_100/v_Feeding_g01_c14.avi',\n",
              " 'Action_100/v_Pumping_g01_c11.avi',\n",
              " 'Action_100/v_Pumping_g01_c39.avi',\n",
              " 'Action_100/v_Feeding_g01_c9.avi',\n",
              " 'Action_100/v_Pumping_g01_c38.avi',\n",
              " 'Action_100/v_Feeding_g01_c8.avi',\n",
              " 'Action_100/v_Pumping_g01_c10.avi',\n",
              " 'Action_100/v_Feeding_g01_c15.avi',\n",
              " 'Action_100/v_Feeding_g01_c29.avi',\n",
              " 'Action_100/v_Grooming_g01_c76.avi',\n",
              " 'Action_100/v_Grooming_g01_c62.avi',\n",
              " 'Action_100/v_Grooming_g01_c89.avi',\n",
              " 'Action_100/v_Grooming_g01_c99.avi',\n",
              " 'Action_100/v_Grooming_g01_c66.avi',\n",
              " 'Action_100/v_Grooming_g01_c72.avi',\n",
              " 'Action_100/v_Feeding_g01_c11.avi',\n",
              " 'Action_100/v_Feeding_g01_c39.avi',\n",
              " 'Action_100/v_Pumping_g01_c28.avi',\n",
              " 'Action_100/v_Pumping_g01_c14.avi',\n",
              " 'Action_100/v_Pumping_g01_c15.avi',\n",
              " 'Action_100/v_Pumping_g01_c29.avi',\n",
              " 'Action_100/v_Feeding_g01_c38.avi',\n",
              " 'Action_100/v_Feeding_g01_c10.avi',\n",
              " 'Action_100/v_Grooming_g01_c73.avi',\n",
              " 'Action_100/v_Grooming_g01_c67.avi',\n",
              " 'Action_100/v_Grooming_g01_c98.avi',\n",
              " 'Action_100/v_Grooming_g01_c71.avi',\n",
              " 'Action_100/v_Grooming_g01_c65.avi',\n",
              " 'Action_100/v_Grooming_g01_c59.avi',\n",
              " 'Action_100/v_Feeding_g01_c12.avi',\n",
              " 'Action_100/v_Pumping_g01_c17.avi',\n",
              " 'Action_100/v_Pumping_g01_c16.avi',\n",
              " 'Action_100/v_Feeding_g01_c13.avi',\n",
              " 'Action_100/v_Grooming_g01_c58.avi',\n",
              " 'Action_100/v_Grooming_g01_c64.avi',\n",
              " 'Action_100/v_Grooming_g01_c70.avi',\n",
              " 'Action_100/v_Grooming_g01_c5.avi',\n",
              " 'Action_100/v_Pumping_g01_c1.avi',\n",
              " 'Action_100/v_Grooming_g01_c17.avi',\n",
              " 'Action_100/v_Feeding_g01_c48.avi',\n",
              " 'Action_100/v_Feeding_g01_c74.avi',\n",
              " 'Action_100/v_Feeding_g01_c60.avi',\n",
              " 'Action_100/v_Pumping_g01_c71.avi',\n",
              " 'Action_100/v_Pumping_g01_c65.avi',\n",
              " 'Action_100/v_Pumping_g01_c59.avi',\n",
              " 'Action_100/v_Pumping_g01_c58.avi',\n",
              " 'Action_100/v_Pumping_g01_c64.avi',\n",
              " 'Action_100/v_Pumping_g01_c70.avi',\n",
              " 'Action_100/v_Feeding_g01_c61.avi',\n",
              " 'Action_100/v_Feeding_g01_c75.avi',\n",
              " 'Action_100/v_Feeding_g01_c49.avi',\n",
              " 'Action_100/v_Grooming_g01_c16.avi',\n",
              " 'Action_100/v_Pumping_g01_c0.avi',\n",
              " 'Action_100/v_Grooming_g01_c4.avi',\n",
              " 'Action_100/v_Grooming_g01_c6.avi',\n",
              " 'Action_100/v_Pumping_g01_c2.avi',\n",
              " 'Action_100/v_Grooming_g01_c28.avi',\n",
              " 'Action_100/v_Grooming_g01_c14.avi',\n",
              " 'Action_100/v_Feeding_g01_c88.avi',\n",
              " 'Action_100/v_Feeding_g01_c63.avi',\n",
              " 'Action_100/v_Feeding_g01_c77.avi',\n",
              " 'Action_100/v_Pumping_g01_c66.avi',\n",
              " 'Action_100/v_Pumping_g01_c72.avi',\n",
              " 'Action_100/v_Pumping_g01_c99.avi',\n",
              " 'Action_100/v_Pumping_g01_c98.avi',\n",
              " 'Action_100/v_Pumping_g01_c73.avi',\n",
              " 'Action_100/v_Pumping_g01_c67.avi',\n",
              " 'Action_100/v_Feeding_g01_c76.avi',\n",
              " 'Action_100/v_Feeding_g01_c62.avi',\n",
              " 'Action_100/v_Feeding_g01_c89.avi',\n",
              " 'Action_100/v_Grooming_g01_c15.avi',\n",
              " 'Action_100/v_Grooming_g01_c29.avi',\n",
              " 'Action_100/v_Pumping_g01_c3.avi',\n",
              " 'Action_100/v_Grooming_g01_c7.avi',\n",
              " 'Action_100/v_Grooming_g01_c3.avi',\n",
              " 'Action_100/v_Pumping_g01_c7.avi',\n",
              " 'Action_100/v_Grooming_g01_c11.avi',\n",
              " 'Action_100/v_Grooming_g01_c39.avi',\n",
              " 'Action_100/v_Feeding_g01_c99.avi',\n",
              " 'Action_100/v_Feeding_g01_c66.avi',\n",
              " 'Action_100/v_Feeding_g01_c72.avi',\n",
              " 'Action_100/v_Pumping_g01_c63.avi',\n",
              " 'Action_100/v_Pumping_g01_c77.avi',\n",
              " 'Action_100/v_Pumping_g01_c88.avi',\n",
              " 'Action_100/v_Pumping_g01_c89.avi',\n",
              " 'Action_100/v_Pumping_g01_c76.avi',\n",
              " 'Action_100/v_Pumping_g01_c62.avi',\n",
              " 'Action_100/v_Feeding_g01_c73.avi',\n",
              " 'Action_100/v_Feeding_g01_c67.avi',\n",
              " 'Action_100/v_Feeding_g01_c98.avi',\n",
              " 'Action_100/v_Grooming_g01_c38.avi',\n",
              " 'Action_100/v_Grooming_g01_c10.avi',\n",
              " 'Action_100/v_Pumping_g01_c6.avi',\n",
              " 'Action_100/v_Grooming_g01_c2.avi',\n",
              " 'Action_100/v_Grooming_g01_c0.avi',\n",
              " 'Action_100/v_Pumping_g01_c4.avi',\n",
              " 'Action_100/v_Grooming_g01_c12.avi',\n",
              " 'Action_100/v_Feeding_g01_c71.avi',\n",
              " 'Action_100/v_Feeding_g01_c65.avi',\n",
              " 'Action_100/v_Feeding_g01_c59.avi',\n",
              " 'Action_100/v_Pumping_g01_c48.avi',\n",
              " 'Action_100/v_Pumping_g01_c74.avi',\n",
              " 'Action_100/v_Pumping_g01_c60.avi',\n",
              " 'Action_100/v_Pumping_g01_c61.avi',\n",
              " 'Action_100/v_Pumping_g01_c75.avi',\n",
              " 'Action_100/v_Pumping_g01_c49.avi',\n",
              " 'Action_100/v_Feeding_g01_c58.avi',\n",
              " 'Action_100/v_Feeding_g01_c64.avi',\n",
              " 'Action_100/v_Feeding_g01_c70.avi',\n",
              " 'Action_100/v_Grooming_g01_c13.avi',\n",
              " 'Action_100/v_Pumping_g01_c5.avi',\n",
              " 'Action_100/v_Grooming_g01_c1.avi']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "files = list_files_from_zip_url(URL)\n",
        "files = [f for f in files if f.endswith('.avi')]\n",
        "(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zKZGEzIuAIfX",
        "outputId": "3fa4d8cb-9752-420b-a10d-a4406c53ebd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Pumping'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "def get_class(fname):\n",
        "  \"\"\" Retrieve the name of the class given a filename.\n",
        "\n",
        "    Args:\n",
        "      fname: Name of the file in the UCF101 dataset.\n",
        "\n",
        "    Returns:\n",
        "      Class that the file belongs to.\n",
        "  \"\"\"\n",
        "  return fname.split('_')[-3]\n",
        "get_class(files[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQeDGLNmAMyh",
        "outputId": "c5a954d4-edd7-4a4b-91a9-c218e1e096e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(list,\n",
              "            {'Pumping': ['Action_100/v_Pumping_g01_c8.avi',\n",
              "              'Action_100/v_Pumping_g01_c50.avi',\n",
              "              'Action_100/v_Pumping_g01_c44.avi',\n",
              "              'Action_100/v_Pumping_g01_c78.avi',\n",
              "              'Action_100/v_Pumping_g01_c93.avi',\n",
              "              'Action_100/v_Pumping_g01_c87.avi',\n",
              "              'Action_100/v_Pumping_g01_c86.avi',\n",
              "              'Action_100/v_Pumping_g01_c92.avi',\n",
              "              'Action_100/v_Pumping_g01_c79.avi',\n",
              "              'Action_100/v_Pumping_g01_c45.avi',\n",
              "              'Action_100/v_Pumping_g01_c51.avi',\n",
              "              'Action_100/v_Pumping_g01_c9.avi',\n",
              "              'Action_100/v_Pumping_g01_c47.avi',\n",
              "              'Action_100/v_Pumping_g01_c53.avi',\n",
              "              'Action_100/v_Pumping_g01_c84.avi',\n",
              "              'Action_100/v_Pumping_g01_c90.avi',\n",
              "              'Action_100/v_Pumping_g01_c91.avi',\n",
              "              'Action_100/v_Pumping_g01_c85.avi',\n",
              "              'Action_100/v_Pumping_g01_c52.avi',\n",
              "              'Action_100/v_Pumping_g01_c46.avi',\n",
              "              'Action_100/v_Pumping_g01_c42.avi',\n",
              "              'Action_100/v_Pumping_g01_c56.avi',\n",
              "              'Action_100/v_Pumping_g01_c81.avi',\n",
              "              'Action_100/v_Pumping_g01_c95.avi',\n",
              "              'Action_100/v_Pumping_g01_c94.avi',\n",
              "              'Action_100/v_Pumping_g01_c80.avi',\n",
              "              'Action_100/v_Pumping_g01_c57.avi',\n",
              "              'Action_100/v_Pumping_g01_c43.avi',\n",
              "              'Action_100/v_Pumping_g01_c69.avi',\n",
              "              'Action_100/v_Pumping_g01_c55.avi',\n",
              "              'Action_100/v_Pumping_g01_c41.avi',\n",
              "              'Action_100/v_Pumping_g01_c96.avi',\n",
              "              'Action_100/v_Pumping_g01_c82.avi',\n",
              "              'Action_100/v_Pumping_g01_c83.avi',\n",
              "              'Action_100/v_Pumping_g01_c97.avi',\n",
              "              'Action_100/v_Pumping_g01_c40.avi',\n",
              "              'Action_100/v_Pumping_g01_c54.avi',\n",
              "              'Action_100/v_Pumping_g01_c68.avi',\n",
              "              'Action_100/v_Pumping_g01_c33.avi',\n",
              "              'Action_100/v_Pumping_g01_c27.avi',\n",
              "              'Action_100/v_Pumping_g01_c26.avi',\n",
              "              'Action_100/v_Pumping_g01_c32.avi',\n",
              "              'Action_100/v_Pumping_g01_c24.avi',\n",
              "              'Action_100/v_Pumping_g01_c30.avi',\n",
              "              'Action_100/v_Pumping_g01_c18.avi',\n",
              "              'Action_100/v_Pumping_g01_c19.avi',\n",
              "              'Action_100/v_Pumping_g01_c31.avi',\n",
              "              'Action_100/v_Pumping_g01_c25.avi',\n",
              "              'Action_100/v_Pumping_g01_c21.avi',\n",
              "              'Action_100/v_Pumping_g01_c35.avi',\n",
              "              'Action_100/v_Pumping_g01_c34.avi',\n",
              "              'Action_100/v_Pumping_g01_c20.avi',\n",
              "              'Action_100/v_Pumping_g01_c36.avi',\n",
              "              'Action_100/v_Pumping_g01_c22.avi',\n",
              "              'Action_100/v_Pumping_g01_c23.avi',\n",
              "              'Action_100/v_Pumping_g01_c37.avi',\n",
              "              'Action_100/v_Pumping_g01_c12.avi',\n",
              "              'Action_100/v_Pumping_g01_c13.avi',\n",
              "              'Action_100/v_Pumping_g01_c11.avi',\n",
              "              'Action_100/v_Pumping_g01_c39.avi',\n",
              "              'Action_100/v_Pumping_g01_c38.avi',\n",
              "              'Action_100/v_Pumping_g01_c10.avi',\n",
              "              'Action_100/v_Pumping_g01_c28.avi',\n",
              "              'Action_100/v_Pumping_g01_c14.avi',\n",
              "              'Action_100/v_Pumping_g01_c15.avi',\n",
              "              'Action_100/v_Pumping_g01_c29.avi',\n",
              "              'Action_100/v_Pumping_g01_c17.avi',\n",
              "              'Action_100/v_Pumping_g01_c16.avi',\n",
              "              'Action_100/v_Pumping_g01_c1.avi',\n",
              "              'Action_100/v_Pumping_g01_c71.avi',\n",
              "              'Action_100/v_Pumping_g01_c65.avi',\n",
              "              'Action_100/v_Pumping_g01_c59.avi',\n",
              "              'Action_100/v_Pumping_g01_c58.avi',\n",
              "              'Action_100/v_Pumping_g01_c64.avi',\n",
              "              'Action_100/v_Pumping_g01_c70.avi',\n",
              "              'Action_100/v_Pumping_g01_c0.avi',\n",
              "              'Action_100/v_Pumping_g01_c2.avi',\n",
              "              'Action_100/v_Pumping_g01_c66.avi',\n",
              "              'Action_100/v_Pumping_g01_c72.avi',\n",
              "              'Action_100/v_Pumping_g01_c99.avi',\n",
              "              'Action_100/v_Pumping_g01_c98.avi',\n",
              "              'Action_100/v_Pumping_g01_c73.avi',\n",
              "              'Action_100/v_Pumping_g01_c67.avi',\n",
              "              'Action_100/v_Pumping_g01_c3.avi',\n",
              "              'Action_100/v_Pumping_g01_c7.avi',\n",
              "              'Action_100/v_Pumping_g01_c63.avi',\n",
              "              'Action_100/v_Pumping_g01_c77.avi',\n",
              "              'Action_100/v_Pumping_g01_c88.avi',\n",
              "              'Action_100/v_Pumping_g01_c89.avi',\n",
              "              'Action_100/v_Pumping_g01_c76.avi',\n",
              "              'Action_100/v_Pumping_g01_c62.avi',\n",
              "              'Action_100/v_Pumping_g01_c6.avi',\n",
              "              'Action_100/v_Pumping_g01_c4.avi',\n",
              "              'Action_100/v_Pumping_g01_c48.avi',\n",
              "              'Action_100/v_Pumping_g01_c74.avi',\n",
              "              'Action_100/v_Pumping_g01_c60.avi',\n",
              "              'Action_100/v_Pumping_g01_c61.avi',\n",
              "              'Action_100/v_Pumping_g01_c75.avi',\n",
              "              'Action_100/v_Pumping_g01_c49.avi',\n",
              "              'Action_100/v_Pumping_g01_c5.avi'],\n",
              "             'Grooming': ['Action_100/v_Grooming_g01_c36.avi',\n",
              "              'Action_100/v_Grooming_g01_c22.avi',\n",
              "              'Action_100/v_Grooming_g01_c23.avi',\n",
              "              'Action_100/v_Grooming_g01_c37.avi',\n",
              "              'Action_100/v_Grooming_g01_c21.avi',\n",
              "              'Action_100/v_Grooming_g01_c35.avi',\n",
              "              'Action_100/v_Grooming_g01_c34.avi',\n",
              "              'Action_100/v_Grooming_g01_c20.avi',\n",
              "              'Action_100/v_Grooming_g01_c24.avi',\n",
              "              'Action_100/v_Grooming_g01_c30.avi',\n",
              "              'Action_100/v_Grooming_g01_c18.avi',\n",
              "              'Action_100/v_Grooming_g01_c19.avi',\n",
              "              'Action_100/v_Grooming_g01_c31.avi',\n",
              "              'Action_100/v_Grooming_g01_c25.avi',\n",
              "              'Action_100/v_Grooming_g01_c9.avi',\n",
              "              'Action_100/v_Grooming_g01_c33.avi',\n",
              "              'Action_100/v_Grooming_g01_c27.avi',\n",
              "              'Action_100/v_Grooming_g01_c26.avi',\n",
              "              'Action_100/v_Grooming_g01_c32.avi',\n",
              "              'Action_100/v_Grooming_g01_c8.avi',\n",
              "              'Action_100/v_Grooming_g01_c96.avi',\n",
              "              'Action_100/v_Grooming_g01_c82.avi',\n",
              "              'Action_100/v_Grooming_g01_c69.avi',\n",
              "              'Action_100/v_Grooming_g01_c55.avi',\n",
              "              'Action_100/v_Grooming_g01_c41.avi',\n",
              "              'Action_100/v_Grooming_g01_c40.avi',\n",
              "              'Action_100/v_Grooming_g01_c54.avi',\n",
              "              'Action_100/v_Grooming_g01_c68.avi',\n",
              "              'Action_100/v_Grooming_g01_c83.avi',\n",
              "              'Action_100/v_Grooming_g01_c97.avi',\n",
              "              'Action_100/v_Grooming_g01_c81.avi',\n",
              "              'Action_100/v_Grooming_g01_c95.avi',\n",
              "              'Action_100/v_Grooming_g01_c42.avi',\n",
              "              'Action_100/v_Grooming_g01_c56.avi',\n",
              "              'Action_100/v_Grooming_g01_c57.avi',\n",
              "              'Action_100/v_Grooming_g01_c43.avi',\n",
              "              'Action_100/v_Grooming_g01_c94.avi',\n",
              "              'Action_100/v_Grooming_g01_c80.avi',\n",
              "              'Action_100/v_Grooming_g01_c84.avi',\n",
              "              'Action_100/v_Grooming_g01_c90.avi',\n",
              "              'Action_100/v_Grooming_g01_c47.avi',\n",
              "              'Action_100/v_Grooming_g01_c53.avi',\n",
              "              'Action_100/v_Grooming_g01_c52.avi',\n",
              "              'Action_100/v_Grooming_g01_c46.avi',\n",
              "              'Action_100/v_Grooming_g01_c91.avi',\n",
              "              'Action_100/v_Grooming_g01_c85.avi',\n",
              "              'Action_100/v_Grooming_g01_c93.avi',\n",
              "              'Action_100/v_Grooming_g01_c87.avi',\n",
              "              'Action_100/v_Grooming_g01_c50.avi',\n",
              "              'Action_100/v_Grooming_g01_c44.avi',\n",
              "              'Action_100/v_Grooming_g01_c78.avi',\n",
              "              'Action_100/v_Grooming_g01_c79.avi',\n",
              "              'Action_100/v_Grooming_g01_c45.avi',\n",
              "              'Action_100/v_Grooming_g01_c51.avi',\n",
              "              'Action_100/v_Grooming_g01_c86.avi',\n",
              "              'Action_100/v_Grooming_g01_c92.avi',\n",
              "              'Action_100/v_Grooming_g01_c48.avi',\n",
              "              'Action_100/v_Grooming_g01_c74.avi',\n",
              "              'Action_100/v_Grooming_g01_c60.avi',\n",
              "              'Action_100/v_Grooming_g01_c61.avi',\n",
              "              'Action_100/v_Grooming_g01_c75.avi',\n",
              "              'Action_100/v_Grooming_g01_c49.avi',\n",
              "              'Action_100/v_Grooming_g01_c88.avi',\n",
              "              'Action_100/v_Grooming_g01_c63.avi',\n",
              "              'Action_100/v_Grooming_g01_c77.avi',\n",
              "              'Action_100/v_Grooming_g01_c76.avi',\n",
              "              'Action_100/v_Grooming_g01_c62.avi',\n",
              "              'Action_100/v_Grooming_g01_c89.avi',\n",
              "              'Action_100/v_Grooming_g01_c99.avi',\n",
              "              'Action_100/v_Grooming_g01_c66.avi',\n",
              "              'Action_100/v_Grooming_g01_c72.avi',\n",
              "              'Action_100/v_Grooming_g01_c73.avi',\n",
              "              'Action_100/v_Grooming_g01_c67.avi',\n",
              "              'Action_100/v_Grooming_g01_c98.avi',\n",
              "              'Action_100/v_Grooming_g01_c71.avi',\n",
              "              'Action_100/v_Grooming_g01_c65.avi',\n",
              "              'Action_100/v_Grooming_g01_c59.avi',\n",
              "              'Action_100/v_Grooming_g01_c58.avi',\n",
              "              'Action_100/v_Grooming_g01_c64.avi',\n",
              "              'Action_100/v_Grooming_g01_c70.avi',\n",
              "              'Action_100/v_Grooming_g01_c5.avi',\n",
              "              'Action_100/v_Grooming_g01_c17.avi',\n",
              "              'Action_100/v_Grooming_g01_c16.avi',\n",
              "              'Action_100/v_Grooming_g01_c4.avi',\n",
              "              'Action_100/v_Grooming_g01_c6.avi',\n",
              "              'Action_100/v_Grooming_g01_c28.avi',\n",
              "              'Action_100/v_Grooming_g01_c14.avi',\n",
              "              'Action_100/v_Grooming_g01_c15.avi',\n",
              "              'Action_100/v_Grooming_g01_c29.avi',\n",
              "              'Action_100/v_Grooming_g01_c7.avi',\n",
              "              'Action_100/v_Grooming_g01_c3.avi',\n",
              "              'Action_100/v_Grooming_g01_c11.avi',\n",
              "              'Action_100/v_Grooming_g01_c39.avi',\n",
              "              'Action_100/v_Grooming_g01_c38.avi',\n",
              "              'Action_100/v_Grooming_g01_c10.avi',\n",
              "              'Action_100/v_Grooming_g01_c2.avi',\n",
              "              'Action_100/v_Grooming_g01_c0.avi',\n",
              "              'Action_100/v_Grooming_g01_c12.avi',\n",
              "              'Action_100/v_Grooming_g01_c13.avi',\n",
              "              'Action_100/v_Grooming_g01_c1.avi'],\n",
              "             'Feeding': ['Action_100/v_Feeding_g01_c96.avi',\n",
              "              'Action_100/v_Feeding_g01_c82.avi',\n",
              "              'Action_100/v_Feeding_g01_c69.avi',\n",
              "              'Action_100/v_Feeding_g01_c55.avi',\n",
              "              'Action_100/v_Feeding_g01_c41.avi',\n",
              "              'Action_100/v_Feeding_g01_c40.avi',\n",
              "              'Action_100/v_Feeding_g01_c54.avi',\n",
              "              'Action_100/v_Feeding_g01_c68.avi',\n",
              "              'Action_100/v_Feeding_g01_c83.avi',\n",
              "              'Action_100/v_Feeding_g01_c97.avi',\n",
              "              'Action_100/v_Feeding_g01_c81.avi',\n",
              "              'Action_100/v_Feeding_g01_c95.avi',\n",
              "              'Action_100/v_Feeding_g01_c42.avi',\n",
              "              'Action_100/v_Feeding_g01_c56.avi',\n",
              "              'Action_100/v_Feeding_g01_c57.avi',\n",
              "              'Action_100/v_Feeding_g01_c43.avi',\n",
              "              'Action_100/v_Feeding_g01_c94.avi',\n",
              "              'Action_100/v_Feeding_g01_c80.avi',\n",
              "              'Action_100/v_Feeding_g01_c84.avi',\n",
              "              'Action_100/v_Feeding_g01_c90.avi',\n",
              "              'Action_100/v_Feeding_g01_c47.avi',\n",
              "              'Action_100/v_Feeding_g01_c53.avi',\n",
              "              'Action_100/v_Feeding_g01_c52.avi',\n",
              "              'Action_100/v_Feeding_g01_c46.avi',\n",
              "              'Action_100/v_Feeding_g01_c91.avi',\n",
              "              'Action_100/v_Feeding_g01_c85.avi',\n",
              "              'Action_100/v_Feeding_g01_c93.avi',\n",
              "              'Action_100/v_Feeding_g01_c87.avi',\n",
              "              'Action_100/v_Feeding_g01_c50.avi',\n",
              "              'Action_100/v_Feeding_g01_c44.avi',\n",
              "              'Action_100/v_Feeding_g01_c78.avi',\n",
              "              'Action_100/v_Feeding_g01_c79.avi',\n",
              "              'Action_100/v_Feeding_g01_c45.avi',\n",
              "              'Action_100/v_Feeding_g01_c51.avi',\n",
              "              'Action_100/v_Feeding_g01_c86.avi',\n",
              "              'Action_100/v_Feeding_g01_c92.avi',\n",
              "              'Action_100/v_Feeding_g01_c36.avi',\n",
              "              'Action_100/v_Feeding_g01_c22.avi',\n",
              "              'Action_100/v_Feeding_g01_c3.avi',\n",
              "              'Action_100/v_Feeding_g01_c2.avi',\n",
              "              'Action_100/v_Feeding_g01_c23.avi',\n",
              "              'Action_100/v_Feeding_g01_c37.avi',\n",
              "              'Action_100/v_Feeding_g01_c21.avi',\n",
              "              'Action_100/v_Feeding_g01_c35.avi',\n",
              "              'Action_100/v_Feeding_g01_c0.avi',\n",
              "              'Action_100/v_Feeding_g01_c1.avi',\n",
              "              'Action_100/v_Feeding_g01_c34.avi',\n",
              "              'Action_100/v_Feeding_g01_c20.avi',\n",
              "              'Action_100/v_Feeding_g01_c24.avi',\n",
              "              'Action_100/v_Feeding_g01_c30.avi',\n",
              "              'Action_100/v_Feeding_g01_c18.avi',\n",
              "              'Action_100/v_Feeding_g01_c5.avi',\n",
              "              'Action_100/v_Feeding_g01_c4.avi',\n",
              "              'Action_100/v_Feeding_g01_c19.avi',\n",
              "              'Action_100/v_Feeding_g01_c31.avi',\n",
              "              'Action_100/v_Feeding_g01_c25.avi',\n",
              "              'Action_100/v_Feeding_g01_c33.avi',\n",
              "              'Action_100/v_Feeding_g01_c27.avi',\n",
              "              'Action_100/v_Feeding_g01_c6.avi',\n",
              "              'Action_100/v_Feeding_g01_c7.avi',\n",
              "              'Action_100/v_Feeding_g01_c26.avi',\n",
              "              'Action_100/v_Feeding_g01_c32.avi',\n",
              "              'Action_100/v_Feeding_g01_c17.avi',\n",
              "              'Action_100/v_Feeding_g01_c16.avi',\n",
              "              'Action_100/v_Feeding_g01_c28.avi',\n",
              "              'Action_100/v_Feeding_g01_c14.avi',\n",
              "              'Action_100/v_Feeding_g01_c9.avi',\n",
              "              'Action_100/v_Feeding_g01_c8.avi',\n",
              "              'Action_100/v_Feeding_g01_c15.avi',\n",
              "              'Action_100/v_Feeding_g01_c29.avi',\n",
              "              'Action_100/v_Feeding_g01_c11.avi',\n",
              "              'Action_100/v_Feeding_g01_c39.avi',\n",
              "              'Action_100/v_Feeding_g01_c38.avi',\n",
              "              'Action_100/v_Feeding_g01_c10.avi',\n",
              "              'Action_100/v_Feeding_g01_c12.avi',\n",
              "              'Action_100/v_Feeding_g01_c13.avi',\n",
              "              'Action_100/v_Feeding_g01_c48.avi',\n",
              "              'Action_100/v_Feeding_g01_c74.avi',\n",
              "              'Action_100/v_Feeding_g01_c60.avi',\n",
              "              'Action_100/v_Feeding_g01_c61.avi',\n",
              "              'Action_100/v_Feeding_g01_c75.avi',\n",
              "              'Action_100/v_Feeding_g01_c49.avi',\n",
              "              'Action_100/v_Feeding_g01_c88.avi',\n",
              "              'Action_100/v_Feeding_g01_c63.avi',\n",
              "              'Action_100/v_Feeding_g01_c77.avi',\n",
              "              'Action_100/v_Feeding_g01_c76.avi',\n",
              "              'Action_100/v_Feeding_g01_c62.avi',\n",
              "              'Action_100/v_Feeding_g01_c89.avi',\n",
              "              'Action_100/v_Feeding_g01_c99.avi',\n",
              "              'Action_100/v_Feeding_g01_c66.avi',\n",
              "              'Action_100/v_Feeding_g01_c72.avi',\n",
              "              'Action_100/v_Feeding_g01_c73.avi',\n",
              "              'Action_100/v_Feeding_g01_c67.avi',\n",
              "              'Action_100/v_Feeding_g01_c98.avi',\n",
              "              'Action_100/v_Feeding_g01_c71.avi',\n",
              "              'Action_100/v_Feeding_g01_c65.avi',\n",
              "              'Action_100/v_Feeding_g01_c59.avi',\n",
              "              'Action_100/v_Feeding_g01_c58.avi',\n",
              "              'Action_100/v_Feeding_g01_c64.avi',\n",
              "              'Action_100/v_Feeding_g01_c70.avi']})"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "def get_files_per_class(files):\n",
        "  \"\"\" Retrieve the files that belong to each class.\n",
        "\n",
        "    Args:\n",
        "      files: List of files in the dataset.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary of class names (key) and files (values).\n",
        "  \"\"\"\n",
        "  files_for_class = collections.defaultdict(list)\n",
        "  for fname in files:\n",
        "    class_name = get_class(fname)\n",
        "    files_for_class[class_name].append(fname)\n",
        "  return files_for_class\n",
        "get_files_per_class(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56YY3_wGAOTI"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 3\n",
        "FILES_PER_CLASS = 100\n",
        "files_for_class = get_files_per_class(files)\n",
        "classes = list(files_for_class.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ito3lZDnAdB2",
        "outputId": "0a2fc56e-79fa-48b8-f022-a7cda10c8247"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num classes: 3\n",
            "Num videos for class[0]: 100\n"
          ]
        }
      ],
      "source": [
        "print('Num classes:', len(classes))\n",
        "print('Num videos for class[0]:', len(files_for_class[classes[2]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcQnZwSNMXhm"
      },
      "outputs": [],
      "source": [
        "def select_subset_of_classes(files_for_class, classes, files_per_class):\n",
        "  \"\"\" Create a dictionary with the class name and a subset of the files in that class.\n",
        "\n",
        "    Args:\n",
        "      files_for_class: Dictionary of class names (key) and files (values).\n",
        "      classes: List of classes.\n",
        "      files_per_class: Number of files per class of interest.\n",
        "\n",
        "    Returns:\n",
        "      Dictionary with class as key and list of specified number of video files in that class.\n",
        "  \"\"\"\n",
        "  files_subset = dict()\n",
        "\n",
        "  for class_name in classes:\n",
        "    class_files = files_for_class[class_name]\n",
        "    files_subset[class_name] = class_files[:files_per_class]\n",
        "\n",
        "  return files_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKJq-GrEMYws",
        "outputId": "a6751553-1d0b-4cb0-8ecf-f121d285f0df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pumping', 'Grooming', 'Feeding']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "files_subset = select_subset_of_classes(files_for_class, classes[:NUM_CLASSES], FILES_PER_CLASS)\n",
        "list(files_subset.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVT3naGzMaNv"
      },
      "outputs": [],
      "source": [
        "def download_from_zip(zip_url, to_dir, file_names):\n",
        "  \"\"\" Download the contents of the zip file from the zip URL.\n",
        "\n",
        "    Args:\n",
        "      zip_url: A URL with a zip file containing data.\n",
        "      to_dir: A directory to download data to.\n",
        "      file_names: Names of files to download.\n",
        "  \"\"\"\n",
        "  with rz.RemoteZip(zip_url) as zip:\n",
        "    for fn in tqdm.tqdm(file_names):\n",
        "      class_name = get_class(fn)\n",
        "      zip.extract(fn, str(to_dir / class_name))\n",
        "      unzipped_file = to_dir / class_name / fn\n",
        "\n",
        "      fn = pathlib.Path(fn).parts[-1]\n",
        "      output_file = to_dir / class_name / fn\n",
        "      unzipped_file.rename(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKpc6bdZMbiE"
      },
      "outputs": [],
      "source": [
        "def split_class_lists(files_for_class, count):\n",
        "  \"\"\" Returns the list of files belonging to a subset of data as well as the remainder of\n",
        "    files that need to be downloaded.\n",
        "\n",
        "    Args:\n",
        "      files_for_class: Files belonging to a particular class of data.\n",
        "      count: Number of files to download.\n",
        "\n",
        "    Returns:\n",
        "      Files belonging to the subset of data and dictionary of the remainder of files that need to be downloaded.\n",
        "  \"\"\"\n",
        "  split_files = []\n",
        "  remainder = {}\n",
        "  for cls in files_for_class:\n",
        "    split_files.extend(files_for_class[cls][:count])\n",
        "    remainder[cls] = files_for_class[cls][count:]\n",
        "  return split_files, remainder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMR34th1McHm"
      },
      "outputs": [],
      "source": [
        "def download_ufc_101_subset(zip_url, num_classes, splits, download_dir):\n",
        "  \"\"\" Download a subset of the UFC101 dataset and split them into various parts, such as\n",
        "    training, validation, and test.\n",
        "\n",
        "    Args:\n",
        "      zip_url: A URL with a ZIP file with the data.\n",
        "      num_classes: Number of labels.\n",
        "      splits: Dictionary specifying the training, validation, test, etc. (key) division of data\n",
        "              (value is number of files per split).\n",
        "      download_dir: Directory to download data to.\n",
        "\n",
        "    Return:\n",
        "      Mapping of the directories containing the subsections of data.\n",
        "  \"\"\"\n",
        "  files = list_files_from_zip_url(zip_url)\n",
        "  files.remove(files[0])\n",
        "  counter=0\n",
        "  print(len(files))\n",
        "\n",
        "  files_for_class = get_files_per_class(files)\n",
        "  print(len(files_for_class['Pumping']))\n",
        "\n",
        "  classes = list(files_for_class.keys())[:num_classes]\n",
        "  for cls in classes:\n",
        "    random.shuffle(files_for_class[cls])\n",
        "\n",
        "  # Only use the number of classes you want in the dictionary\n",
        "  files_for_class = {x: files_for_class[x] for x in classes}\n",
        "  print(files_for_class)\n",
        "  print(len(files_for_class['Pumping']))\n",
        "\n",
        "  dirs = {}\n",
        "\n",
        "  for split_name, split_count in splits.items():\n",
        "     print(split_name, \":\")\n",
        "     split_dir = download_dir / split_name\n",
        "     split_files, files_for_class = split_class_lists(files_for_class, split_count)\n",
        "\n",
        "     print(split_name, len(split_files))\n",
        "     download_from_zip(zip_url, split_dir, split_files)\n",
        "     dirs[split_name] = split_dir\n",
        "\n",
        "  return dirs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_OALAaISQjR"
      },
      "source": [
        "# Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfis5eIrMeTe",
        "outputId": "051fdb17-3ddd-484a-fff1-4b165b04686d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "100\n",
            "{'Pumping': ['Action_100/v_Pumping_g01_c76.avi', 'Action_100/v_Pumping_g01_c77.avi', 'Action_100/v_Pumping_g01_c54.avi', 'Action_100/v_Pumping_g01_c9.avi', 'Action_100/v_Pumping_g01_c8.avi', 'Action_100/v_Pumping_g01_c63.avi', 'Action_100/v_Pumping_g01_c52.avi', 'Action_100/v_Pumping_g01_c11.avi', 'Action_100/v_Pumping_g01_c99.avi', 'Action_100/v_Pumping_g01_c42.avi', 'Action_100/v_Pumping_g01_c34.avi', 'Action_100/v_Pumping_g01_c4.avi', 'Action_100/v_Pumping_g01_c84.avi', 'Action_100/v_Pumping_g01_c96.avi', 'Action_100/v_Pumping_g01_c55.avi', 'Action_100/v_Pumping_g01_c33.avi', 'Action_100/v_Pumping_g01_c71.avi', 'Action_100/v_Pumping_g01_c78.avi', 'Action_100/v_Pumping_g01_c46.avi', 'Action_100/v_Pumping_g01_c93.avi', 'Action_100/v_Pumping_g01_c61.avi', 'Action_100/v_Pumping_g01_c83.avi', 'Action_100/v_Pumping_g01_c1.avi', 'Action_100/v_Pumping_g01_c95.avi', 'Action_100/v_Pumping_g01_c91.avi', 'Action_100/v_Pumping_g01_c17.avi', 'Action_100/v_Pumping_g01_c10.avi', 'Action_100/v_Pumping_g01_c36.avi', 'Action_100/v_Pumping_g01_c12.avi', 'Action_100/v_Pumping_g01_c39.avi', 'Action_100/v_Pumping_g01_c64.avi', 'Action_100/v_Pumping_g01_c82.avi', 'Action_100/v_Pumping_g01_c65.avi', 'Action_100/v_Pumping_g01_c32.avi', 'Action_100/v_Pumping_g01_c21.avi', 'Action_100/v_Pumping_g01_c85.avi', 'Action_100/v_Pumping_g01_c67.avi', 'Action_100/v_Pumping_g01_c86.avi', 'Action_100/v_Pumping_g01_c89.avi', 'Action_100/v_Pumping_g01_c3.avi', 'Action_100/v_Pumping_g01_c40.avi', 'Action_100/v_Pumping_g01_c20.avi', 'Action_100/v_Pumping_g01_c2.avi', 'Action_100/v_Pumping_g01_c14.avi', 'Action_100/v_Pumping_g01_c45.avi', 'Action_100/v_Pumping_g01_c27.avi', 'Action_100/v_Pumping_g01_c57.avi', 'Action_100/v_Pumping_g01_c24.avi', 'Action_100/v_Pumping_g01_c7.avi', 'Action_100/v_Pumping_g01_c80.avi', 'Action_100/v_Pumping_g01_c87.avi', 'Action_100/v_Pumping_g01_c43.avi', 'Action_100/v_Pumping_g01_c58.avi', 'Action_100/v_Pumping_g01_c62.avi', 'Action_100/v_Pumping_g01_c59.avi', 'Action_100/v_Pumping_g01_c37.avi', 'Action_100/v_Pumping_g01_c56.avi', 'Action_100/v_Pumping_g01_c16.avi', 'Action_100/v_Pumping_g01_c15.avi', 'Action_100/v_Pumping_g01_c19.avi', 'Action_100/v_Pumping_g01_c47.avi', 'Action_100/v_Pumping_g01_c75.avi', 'Action_100/v_Pumping_g01_c69.avi', 'Action_100/v_Pumping_g01_c31.avi', 'Action_100/v_Pumping_g01_c26.avi', 'Action_100/v_Pumping_g01_c44.avi', 'Action_100/v_Pumping_g01_c81.avi', 'Action_100/v_Pumping_g01_c6.avi', 'Action_100/v_Pumping_g01_c35.avi', 'Action_100/v_Pumping_g01_c18.avi', 'Action_100/v_Pumping_g01_c51.avi', 'Action_100/v_Pumping_g01_c38.avi', 'Action_100/v_Pumping_g01_c97.avi', 'Action_100/v_Pumping_g01_c22.avi', 'Action_100/v_Pumping_g01_c90.avi', 'Action_100/v_Pumping_g01_c68.avi', 'Action_100/v_Pumping_g01_c98.avi', 'Action_100/v_Pumping_g01_c94.avi', 'Action_100/v_Pumping_g01_c13.avi', 'Action_100/v_Pumping_g01_c60.avi', 'Action_100/v_Pumping_g01_c70.avi', 'Action_100/v_Pumping_g01_c79.avi', 'Action_100/v_Pumping_g01_c25.avi', 'Action_100/v_Pumping_g01_c28.avi', 'Action_100/v_Pumping_g01_c23.avi', 'Action_100/v_Pumping_g01_c53.avi', 'Action_100/v_Pumping_g01_c88.avi', 'Action_100/v_Pumping_g01_c29.avi', 'Action_100/v_Pumping_g01_c72.avi', 'Action_100/v_Pumping_g01_c73.avi', 'Action_100/v_Pumping_g01_c30.avi', 'Action_100/v_Pumping_g01_c41.avi', 'Action_100/v_Pumping_g01_c48.avi', 'Action_100/v_Pumping_g01_c50.avi', 'Action_100/v_Pumping_g01_c66.avi', 'Action_100/v_Pumping_g01_c5.avi', 'Action_100/v_Pumping_g01_c92.avi', 'Action_100/v_Pumping_g01_c49.avi', 'Action_100/v_Pumping_g01_c74.avi', 'Action_100/v_Pumping_g01_c0.avi'], 'Grooming': ['Action_100/v_Grooming_g01_c27.avi', 'Action_100/v_Grooming_g01_c70.avi', 'Action_100/v_Grooming_g01_c96.avi', 'Action_100/v_Grooming_g01_c66.avi', 'Action_100/v_Grooming_g01_c97.avi', 'Action_100/v_Grooming_g01_c63.avi', 'Action_100/v_Grooming_g01_c92.avi', 'Action_100/v_Grooming_g01_c54.avi', 'Action_100/v_Grooming_g01_c72.avi', 'Action_100/v_Grooming_g01_c86.avi', 'Action_100/v_Grooming_g01_c10.avi', 'Action_100/v_Grooming_g01_c52.avi', 'Action_100/v_Grooming_g01_c78.avi', 'Action_100/v_Grooming_g01_c51.avi', 'Action_100/v_Grooming_g01_c79.avi', 'Action_100/v_Grooming_g01_c41.avi', 'Action_100/v_Grooming_g01_c13.avi', 'Action_100/v_Grooming_g01_c38.avi', 'Action_100/v_Grooming_g01_c33.avi', 'Action_100/v_Grooming_g01_c37.avi', 'Action_100/v_Grooming_g01_c46.avi', 'Action_100/v_Grooming_g01_c8.avi', 'Action_100/v_Grooming_g01_c82.avi', 'Action_100/v_Grooming_g01_c23.avi', 'Action_100/v_Grooming_g01_c24.avi', 'Action_100/v_Grooming_g01_c48.avi', 'Action_100/v_Grooming_g01_c99.avi', 'Action_100/v_Grooming_g01_c17.avi', 'Action_100/v_Grooming_g01_c18.avi', 'Action_100/v_Grooming_g01_c9.avi', 'Action_100/v_Grooming_g01_c64.avi', 'Action_100/v_Grooming_g01_c22.avi', 'Action_100/v_Grooming_g01_c69.avi', 'Action_100/v_Grooming_g01_c50.avi', 'Action_100/v_Grooming_g01_c53.avi', 'Action_100/v_Grooming_g01_c93.avi', 'Action_100/v_Grooming_g01_c25.avi', 'Action_100/v_Grooming_g01_c2.avi', 'Action_100/v_Grooming_g01_c83.avi', 'Action_100/v_Grooming_g01_c19.avi', 'Action_100/v_Grooming_g01_c14.avi', 'Action_100/v_Grooming_g01_c80.avi', 'Action_100/v_Grooming_g01_c60.avi', 'Action_100/v_Grooming_g01_c44.avi', 'Action_100/v_Grooming_g01_c20.avi', 'Action_100/v_Grooming_g01_c81.avi', 'Action_100/v_Grooming_g01_c45.avi', 'Action_100/v_Grooming_g01_c57.avi', 'Action_100/v_Grooming_g01_c58.avi', 'Action_100/v_Grooming_g01_c90.avi', 'Action_100/v_Grooming_g01_c73.avi', 'Action_100/v_Grooming_g01_c67.avi', 'Action_100/v_Grooming_g01_c91.avi', 'Action_100/v_Grooming_g01_c98.avi', 'Action_100/v_Grooming_g01_c65.avi', 'Action_100/v_Grooming_g01_c85.avi', 'Action_100/v_Grooming_g01_c62.avi', 'Action_100/v_Grooming_g01_c88.avi', 'Action_100/v_Grooming_g01_c30.avi', 'Action_100/v_Grooming_g01_c34.avi', 'Action_100/v_Grooming_g01_c94.avi', 'Action_100/v_Grooming_g01_c61.avi', 'Action_100/v_Grooming_g01_c0.avi', 'Action_100/v_Grooming_g01_c16.avi', 'Action_100/v_Grooming_g01_c55.avi', 'Action_100/v_Grooming_g01_c15.avi', 'Action_100/v_Grooming_g01_c71.avi', 'Action_100/v_Grooming_g01_c29.avi', 'Action_100/v_Grooming_g01_c7.avi', 'Action_100/v_Grooming_g01_c11.avi', 'Action_100/v_Grooming_g01_c74.avi', 'Action_100/v_Grooming_g01_c68.avi', 'Action_100/v_Grooming_g01_c21.avi', 'Action_100/v_Grooming_g01_c35.avi', 'Action_100/v_Grooming_g01_c47.avi', 'Action_100/v_Grooming_g01_c5.avi', 'Action_100/v_Grooming_g01_c28.avi', 'Action_100/v_Grooming_g01_c43.avi', 'Action_100/v_Grooming_g01_c36.avi', 'Action_100/v_Grooming_g01_c40.avi', 'Action_100/v_Grooming_g01_c26.avi', 'Action_100/v_Grooming_g01_c3.avi', 'Action_100/v_Grooming_g01_c49.avi', 'Action_100/v_Grooming_g01_c89.avi', 'Action_100/v_Grooming_g01_c12.avi', 'Action_100/v_Grooming_g01_c31.avi', 'Action_100/v_Grooming_g01_c4.avi', 'Action_100/v_Grooming_g01_c59.avi', 'Action_100/v_Grooming_g01_c84.avi', 'Action_100/v_Grooming_g01_c87.avi', 'Action_100/v_Grooming_g01_c1.avi', 'Action_100/v_Grooming_g01_c42.avi', 'Action_100/v_Grooming_g01_c75.avi', 'Action_100/v_Grooming_g01_c56.avi', 'Action_100/v_Grooming_g01_c77.avi', 'Action_100/v_Grooming_g01_c32.avi', 'Action_100/v_Grooming_g01_c39.avi', 'Action_100/v_Grooming_g01_c95.avi', 'Action_100/v_Grooming_g01_c6.avi', 'Action_100/v_Grooming_g01_c76.avi'], 'Feeding': ['Action_100/v_Feeding_g01_c42.avi', 'Action_100/v_Feeding_g01_c18.avi', 'Action_100/v_Feeding_g01_c4.avi', 'Action_100/v_Feeding_g01_c26.avi', 'Action_100/v_Feeding_g01_c62.avi', 'Action_100/v_Feeding_g01_c78.avi', 'Action_100/v_Feeding_g01_c23.avi', 'Action_100/v_Feeding_g01_c70.avi', 'Action_100/v_Feeding_g01_c29.avi', 'Action_100/v_Feeding_g01_c37.avi', 'Action_100/v_Feeding_g01_c44.avi', 'Action_100/v_Feeding_g01_c66.avi', 'Action_100/v_Feeding_g01_c35.avi', 'Action_100/v_Feeding_g01_c33.avi', 'Action_100/v_Feeding_g01_c75.avi', 'Action_100/v_Feeding_g01_c73.avi', 'Action_100/v_Feeding_g01_c68.avi', 'Action_100/v_Feeding_g01_c34.avi', 'Action_100/v_Feeding_g01_c39.avi', 'Action_100/v_Feeding_g01_c46.avi', 'Action_100/v_Feeding_g01_c13.avi', 'Action_100/v_Feeding_g01_c67.avi', 'Action_100/v_Feeding_g01_c28.avi', 'Action_100/v_Feeding_g01_c14.avi', 'Action_100/v_Feeding_g01_c12.avi', 'Action_100/v_Feeding_g01_c89.avi', 'Action_100/v_Feeding_g01_c10.avi', 'Action_100/v_Feeding_g01_c41.avi', 'Action_100/v_Feeding_g01_c38.avi', 'Action_100/v_Feeding_g01_c79.avi', 'Action_100/v_Feeding_g01_c97.avi', 'Action_100/v_Feeding_g01_c55.avi', 'Action_100/v_Feeding_g01_c7.avi', 'Action_100/v_Feeding_g01_c53.avi', 'Action_100/v_Feeding_g01_c48.avi', 'Action_100/v_Feeding_g01_c6.avi', 'Action_100/v_Feeding_g01_c64.avi', 'Action_100/v_Feeding_g01_c72.avi', 'Action_100/v_Feeding_g01_c32.avi', 'Action_100/v_Feeding_g01_c51.avi', 'Action_100/v_Feeding_g01_c86.avi', 'Action_100/v_Feeding_g01_c9.avi', 'Action_100/v_Feeding_g01_c80.avi', 'Action_100/v_Feeding_g01_c98.avi', 'Action_100/v_Feeding_g01_c21.avi', 'Action_100/v_Feeding_g01_c20.avi', 'Action_100/v_Feeding_g01_c85.avi', 'Action_100/v_Feeding_g01_c74.avi', 'Action_100/v_Feeding_g01_c15.avi', 'Action_100/v_Feeding_g01_c82.avi', 'Action_100/v_Feeding_g01_c43.avi', 'Action_100/v_Feeding_g01_c61.avi', 'Action_100/v_Feeding_g01_c27.avi', 'Action_100/v_Feeding_g01_c52.avi', 'Action_100/v_Feeding_g01_c56.avi', 'Action_100/v_Feeding_g01_c47.avi', 'Action_100/v_Feeding_g01_c25.avi', 'Action_100/v_Feeding_g01_c50.avi', 'Action_100/v_Feeding_g01_c58.avi', 'Action_100/v_Feeding_g01_c5.avi', 'Action_100/v_Feeding_g01_c81.avi', 'Action_100/v_Feeding_g01_c8.avi', 'Action_100/v_Feeding_g01_c19.avi', 'Action_100/v_Feeding_g01_c16.avi', 'Action_100/v_Feeding_g01_c84.avi', 'Action_100/v_Feeding_g01_c49.avi', 'Action_100/v_Feeding_g01_c60.avi', 'Action_100/v_Feeding_g01_c96.avi', 'Action_100/v_Feeding_g01_c3.avi', 'Action_100/v_Feeding_g01_c94.avi', 'Action_100/v_Feeding_g01_c11.avi', 'Action_100/v_Feeding_g01_c59.avi', 'Action_100/v_Feeding_g01_c93.avi', 'Action_100/v_Feeding_g01_c2.avi', 'Action_100/v_Feeding_g01_c31.avi', 'Action_100/v_Feeding_g01_c91.avi', 'Action_100/v_Feeding_g01_c36.avi', 'Action_100/v_Feeding_g01_c24.avi', 'Action_100/v_Feeding_g01_c99.avi', 'Action_100/v_Feeding_g01_c90.avi', 'Action_100/v_Feeding_g01_c1.avi', 'Action_100/v_Feeding_g01_c0.avi', 'Action_100/v_Feeding_g01_c65.avi', 'Action_100/v_Feeding_g01_c77.avi', 'Action_100/v_Feeding_g01_c57.avi', 'Action_100/v_Feeding_g01_c71.avi', 'Action_100/v_Feeding_g01_c88.avi', 'Action_100/v_Feeding_g01_c17.avi', 'Action_100/v_Feeding_g01_c76.avi', 'Action_100/v_Feeding_g01_c22.avi', 'Action_100/v_Feeding_g01_c63.avi', 'Action_100/v_Feeding_g01_c54.avi', 'Action_100/v_Feeding_g01_c92.avi', 'Action_100/v_Feeding_g01_c95.avi', 'Action_100/v_Feeding_g01_c45.avi', 'Action_100/v_Feeding_g01_c30.avi', 'Action_100/v_Feeding_g01_c69.avi', 'Action_100/v_Feeding_g01_c83.avi', 'Action_100/v_Feeding_g01_c87.avi', 'Action_100/v_Feeding_g01_c40.avi']}\n",
            "100\n",
            "train :\n",
            "train 240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 240/240 [03:46<00:00,  1.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test :\n",
            "test 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60/60 [00:50<00:00,  1.18it/s]\n"
          ]
        }
      ],
      "source": [
        "download_dir = pathlib.Path('./Action_subset/')\n",
        "subset_paths = download_ufc_101_subset(URL,\n",
        "                                       num_classes = 3,\n",
        "                                       splits = {\"train\": 80, \"test\": 20},\n",
        "                                       download_dir = download_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning"
      ],
      "metadata": {
        "id": "-m7e7a9pex-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Function"
      ],
      "metadata": {
        "id": "bYVmJrHNfnz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_frames(frame, output_size):\n",
        "  \"\"\"\n",
        "    Pad and resize an image from a video.\n",
        "\n",
        "    Args:\n",
        "      frame: Image that needs to resized and padded.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      Formatted frame with padding of specified output size.\n",
        "  \"\"\"\n",
        "  frame = tf.image.convert_image_dtype(frame, tf.float32)\n",
        "  frame = tf.image.resize_with_pad(frame, *output_size)\n",
        "  return frame\n",
        "\n",
        "def frames_from_video_file(video_path, n_frames, output_size = (224,224), frame_step = 15):\n",
        "  \"\"\"\n",
        "    Creates frames from each video file present for each category.\n",
        "\n",
        "    Args:\n",
        "      video_path: File path to the video.\n",
        "      n_frames: Number of frames to be created per video file.\n",
        "      output_size: Pixel size of the output frame image.\n",
        "\n",
        "    Return:\n",
        "      An NumPy array of frames in the shape of (n_frames, height, width, channels).\n",
        "  \"\"\"\n",
        "  # Read each video frame by frame\n",
        "  result = []\n",
        "  src = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "  video_length = src.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "\n",
        "  need_length = 1 + (n_frames - 1) * frame_step\n",
        "\n",
        "  if need_length > video_length:\n",
        "    start = 0\n",
        "  else:\n",
        "    max_start = video_length - need_length\n",
        "    start = random.randint(0, max_start + 1)\n",
        "\n",
        "  src.set(cv2.CAP_PROP_POS_FRAMES, start)\n",
        "  # ret is a boolean indicating whether read was successful, frame is the image itself\n",
        "  ret, frame = src.read()\n",
        "  result.append(format_frames(frame, output_size))\n",
        "\n",
        "  for _ in range(n_frames - 1):\n",
        "    for _ in range(frame_step):\n",
        "      ret, frame = src.read()\n",
        "    if ret:\n",
        "      frame = format_frames(frame, output_size)\n",
        "      result.append(frame)\n",
        "    else:\n",
        "      result.append(np.zeros_like(result[0]))\n",
        "  src.release()\n",
        "  result = np.array(result)[..., [2, 1, 0]]\n",
        "\n",
        "  return result\n",
        "\n",
        "class FrameGenerator:\n",
        "  def __init__(self, path, n_frames, training = False):\n",
        "    \"\"\" Returns a set of frames with their associated label.\n",
        "\n",
        "      Args:\n",
        "        path: Video file paths.\n",
        "        n_frames: Number of frames.\n",
        "        training: Boolean to determine if training dataset is being created.\n",
        "    \"\"\"\n",
        "    self.path = path\n",
        "    self.n_frames = n_frames\n",
        "    self.training = training\n",
        "    self.class_names = sorted(set(p.name for p in self.path.iterdir() if p.is_dir()))\n",
        "    self.class_ids_for_name = dict((name, idx) for idx, name in enumerate(self.class_names))\n",
        "\n",
        "  def get_files_and_class_names(self):\n",
        "    video_paths = list(self.path.glob('*/*.avi'))\n",
        "    classes = [p.parent.name for p in video_paths]\n",
        "    return video_paths, classes\n",
        "\n",
        "  def __call__(self):\n",
        "    video_paths, classes = self.get_files_and_class_names()\n",
        "\n",
        "    pairs = list(zip(video_paths, classes))\n",
        "\n",
        "    if self.training:\n",
        "      random.shuffle(pairs)\n",
        "\n",
        "    for path, name in pairs:\n",
        "      video_frames = frames_from_video_file(path, self.n_frames)\n",
        "      label = self.class_ids_for_name[name] # Encode labels\n",
        "      yield video_frames, label"
      ],
      "metadata": {
        "id": "s-iBWaaue5AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 8\n",
        "num_frames = 8\n",
        "\n",
        "output_signature = (tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
        "                    tf.TensorSpec(shape = (), dtype = tf.int16))\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['train'], num_frames, training = True),\n",
        "                                          output_signature = output_signature)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(FrameGenerator(subset_paths['test'], num_frames),\n",
        "                                         output_signature = output_signature)\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "metadata": {
        "id": "KHeK6ANEe0hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frames, labels in train_ds.take(10):\n",
        "  print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBnXJ2Ege8ej",
        "outputId": "62f0feed-78d7-44e7-d6d9-a93174db261c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 0 2 0 2 0 1 0], shape=(8,), dtype=int16)\n",
            "tf.Tensor([0 1 2 1 1 1 0 0], shape=(8,), dtype=int16)\n",
            "tf.Tensor([1 0 2 0 1 1 0 0], shape=(8,), dtype=int16)\n",
            "tf.Tensor([2 0 0 1 0 2 2 2], shape=(8,), dtype=int16)\n",
            "tf.Tensor([1 2 2 1 1 2 2 0], shape=(8,), dtype=int16)\n",
            "tf.Tensor([1 0 2 2 0 2 1 1], shape=(8,), dtype=int16)\n",
            "tf.Tensor([1 0 2 1 0 0 0 2], shape=(8,), dtype=int16)\n",
            "tf.Tensor([2 1 2 0 0 0 2 0], shape=(8,), dtype=int16)\n",
            "tf.Tensor([1 2 0 2 0 1 2 0], shape=(8,), dtype=int16)\n",
            "tf.Tensor([1 2 0 2 2 1 2 0], shape=(8,), dtype=int16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Movinet"
      ],
      "metadata": {
        "id": "CV951EoafxQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gru = layers.GRU(units=4, return_sequences=True, return_state=True)\n",
        "\n",
        "inputs = tf.random.normal(shape=[1, 10, 8]) # (batch, sequence, channels)\n",
        "\n",
        "result, state = gru(inputs) # Run it all at once"
      ],
      "metadata": {
        "id": "p88MQdCLf0-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_half, state = gru(inputs[:, :5, :])   # run the first half, and capture the state\n",
        "second_half, _ = gru(inputs[:,5:, :], initial_state=state)  # Use the state to continue where you left off.\n",
        "\n",
        "print(np.allclose(result[:, :5,:], first_half))\n",
        "print(np.allclose(result[:, 5:,:], second_half))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7heY-PZAf3Op",
        "outputId": "efd1979c-e052-4714-ef81-043ba6951511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = 'a0'\n",
        "resolution = 224\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "backbone = movinet.Movinet(model_id=model_id)\n",
        "backbone.trainable = False\n",
        "\n",
        "# Set num_classes=600 to load the pre-trained weights from the original model\n",
        "model = movinet_model.MovinetClassifier(backbone=backbone, num_classes=600)\n",
        "model.build([None, None, None, None, 3])\n",
        "\n",
        "# Load pre-trained weights\n",
        "!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a0_base.tar.gz -O movinet_a0_base.tar.gz -q\n",
        "!tar -xvf movinet_a0_base.tar.gz\n",
        "\n",
        "checkpoint_dir = f'movinet_{model_id}_base'\n",
        "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "status = checkpoint.restore(checkpoint_path)\n",
        "status.assert_existing_objects_matched()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHabkeYDgBTS",
        "outputId": "34cc6e36-beb7-4077-ba29-c814996d3a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movinet_a0_base/\n",
            "movinet_a0_base/checkpoint\n",
            "movinet_a0_base/ckpt-1.data-00000-of-00001\n",
            "movinet_a0_base/ckpt-1.index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7bf8d84affd0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
        "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone=backbone,\n",
        "      num_classes=num_classes)\n",
        "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "rr-smSxngoz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build a classifier, create a function that takes the backbone and the number of classes in a dataset. The build_classifier function will take the backbone and the number of classes in a dataset to build the classifier. In this case, the new classifier will take a num_classes outputs (10 classes for this subset of UCF101). Last parameter will be 3 for this example."
      ],
      "metadata": {
        "id": "X_k40Msygvfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_classifier(batch_size, num_frames, resolution, backbone, 3)"
      ],
      "metadata": {
        "id": "WQCP2cSQgtmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "\n",
        "loss_obj = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "model.compile(loss=loss_obj, optimizer=optimizer, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dEA1EPjpg5S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(train_ds,\n",
        "                    validation_data=test_ds,\n",
        "                    epochs=num_epochs,\n",
        "                    validation_freq=1,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKiU-rlZg6tE",
        "outputId": "51dd39c9-3691-4a65-a507-1cf652ccc2df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "30/30 [==============================] - 203s 6s/step - loss: 0.6154 - accuracy: 0.7750 - val_loss: 0.4959 - val_accuracy: 0.8167\n",
            "Epoch 2/2\n",
            "30/30 [==============================] - 166s 6s/step - loss: 0.2925 - accuracy: 0.8792 - val_loss: 0.4424 - val_accuracy: 0.8500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_ds, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJgx9vrjismF",
        "outputId": "1955dffd-29f7-4be8-acc5-1070b6d02571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 37s 4s/step - loss: 0.3845 - accuracy: 0.8500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 0.38451582193374634, 'accuracy': 0.8500000238418579}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing"
      ],
      "metadata": {
        "id": "y2hOVJgMjjkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_actual_predicted_labels(dataset):\n",
        "  \"\"\"\n",
        "    Create a list of actual ground truth values and the predictions from the model.\n",
        "\n",
        "    Args:\n",
        "      dataset: An iterable data structure, such as a TensorFlow Dataset, with features and labels.\n",
        "\n",
        "    Return:\n",
        "      Ground truth and predicted values for a particular dataset.\n",
        "  \"\"\"\n",
        "  actual = [labels for _, labels in dataset.unbatch()]\n",
        "  predicted = model.predict(dataset)\n",
        "\n",
        "  actual = tf.stack(actual, axis=0)\n",
        "  predicted = tf.concat(predicted, axis=0)\n",
        "  predicted = tf.argmax(predicted, axis=1)\n",
        "\n",
        "  return actual, predicted\n",
        "\n",
        "def plot_confusion_matrix(actual, predicted, labels, ds_type):\n",
        "  cm = tf.math.confusion_matrix(actual, predicted)\n",
        "  ax = sns.heatmap(cm, annot=True, fmt='g')\n",
        "  sns.set(rc={'figure.figsize':(12, 12)})\n",
        "  sns.set(font_scale=1.4)\n",
        "  ax.set_title('Confusion matrix of action recognition for ' + ds_type)\n",
        "  ax.set_xlabel('Predicted Action')\n",
        "  ax.set_ylabel('Actual Action')\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.yticks(rotation=0)\n",
        "  ax.xaxis.set_ticklabels(labels)\n",
        "  ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "G9LhkGxOjpon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fg = FrameGenerator(subset_paths['train'], num_frames, training = True)\n",
        "label_names = list(fg.class_ids_for_name.keys())"
      ],
      "metadata": {
        "id": "qF8y9MVbjtvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual, predicted = get_actual_predicted_labels(test_ds)\n",
        "plot_confusion_matrix(actual, predicted, label_names, 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ydFqea_jxwi",
        "outputId": "cfbf5298-0d8e-4f40-e343-feb1498afffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 44s 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Predictions"
      ],
      "metadata": {
        "id": "EI_upNAokO9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/tensorflow/models/tree/master/official/projects/movinet#prediction-examples"
      ],
      "metadata": {
        "id": "-l2Ur77Bs3v-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = tf.ones([1, 8, 172, 172, 3])\n",
        "example_output = model(example_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBTAaiUuq_hc",
        "outputId": "7aa832d9-8119-41bd-bb9c-92263bad7e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x7bf950660490>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <bound method Conv.call of <official.vision.modeling.layers.nn_layers.Conv3D object at 0x7bf9506637c0>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.ones([1, 8, 172, 172, 3])"
      ],
      "metadata": {
        "id": "KI9T5hm5s2Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the model prediction.\n",
        "output = model(inputs)\n",
        "prediction = tf.argmax(output, -1)"
      ],
      "metadata": {
        "id": "b1t82J2ls5TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgv61_7EtDIW",
        "outputId": "9c0b373f-2182-494c-ff9a-14c303d76a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2], shape=(1,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(example_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH70_u1xrGyf",
        "outputId": "8fb585b8-d1b8-439d-8bb2-2fa07e43702d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[-0.4959383  -0.15950088  0.7142853 ]], shape=(1, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#warmup\n",
        "sig(image = jumpingjack[tf.newaxis, :1]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "5slFYrzDkRae",
        "outputId": "6b76a36e-871a-41b4-8fbd-ae3c1ae1587a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-acd3661795c8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjumpingjack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sig' is not defined"
          ]
        }
      ]
    }
  ]
}